{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bit90647246baa34bc08f445094bb6fdfaa",
   "display_name": "Python 3.8.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('galaxy_catalogue.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "u-g        1.85765\ng-r        0.67158\nr-i        0.4231\ni-z        0.3061\necc        0.585428\nm4_u       2.25195\nm4_g       2.33985\nm4_r       2.38065\nm4_i       2.35974\nm4_z       2.39553\npetroR50_u 3.09512\npetroR50_r 3.81892\npetroR50_z 3.82623\npetroR90_u 5.17481\npetroR90_r 8.26301\npetroR90_z 11.4773\nclass      merger\n"
     ]
    }
   ],
   "source": [
    "for name, value in zip(data.dtype.names, data[0]):\n",
    "  print('{:10} {:.6}'.format(name, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def splitdata_train_test(data, fraction_training):\n",
    "    train_size = int(data.shape[0] * fraction_training)\n",
    "    return train_test_split(data, train_size=train_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number data galaxies: 780\nTrain fraction: 0.7\nNumber of galaxies in training set: 546\nNumber of galaxies in testing set: 234\n"
     ]
    }
   ],
   "source": [
    "data = np.load('galaxy_catalogue.npy')\n",
    "\n",
    "# set the fraction of data which should be in the training set\n",
    "fraction_training = 0.7\n",
    "\n",
    "# split the data using your function\n",
    "training, testing = splitdata_train_test(data, fraction_training)\n",
    "\n",
    "# print the key values\n",
    "print('Number data galaxies:', len(data))\n",
    "print('Train fraction:', fraction_training)\n",
    "print('Number of galaxies in training set:', len(training))\n",
    "print('Number of galaxies in testing set:', len(testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features_targets(data):\n",
    "  # complete the function by calculating the concentrations\n",
    "\n",
    "  targets = data['class']\n",
    "\n",
    "  features = np.empty(shape=(len(data), 13))\n",
    "  features[:, 0] = data['u-g']\n",
    "  features[:, 1] = data['g-r']\n",
    "  features[:, 2] = data['r-i']\n",
    "  features[:, 3] = data['i-z']\n",
    "  features[:, 4] = data['ecc']\n",
    "  features[:, 5] = data['m4_u']\n",
    "  features[:, 6] = data['m4_g']\n",
    "  features[:, 7] = data['m4_r']\n",
    "  features[:, 8] = data['m4_i']\n",
    "  features[:, 9] = data['m4_z']\n",
    "\n",
    "  # fill the remaining 3 columns with concentrations in the u, r and z filters\n",
    "  # concentration in u filter\n",
    "  features[:, 10] = data['petroR50_u'] / data['petroR90_u']\n",
    "  # concentration in r filter\n",
    "  features[:, 11] = data['petroR50_r'] / data['petroR90_r']\n",
    "  # concentration in z filter\n",
    "  features[:, 12] = data['petroR50_z'] / data['petroR90_z']\n",
    "\n",
    "  return features, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Features shape: (780, 13)\nTargets shape: (780,)\n"
     ]
    }
   ],
   "source": [
    "data = np.load('galaxy_catalogue.npy')\n",
    "\n",
    "features, targets = generate_features_targets(data)\n",
    "\n",
    "# Print the shape of each array to check the arrays are the correct dimensions. \n",
    "print(\"Features shape:\", features.shape)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def dtc_predict_actual(data):\n",
    "  # split the data into training and testing sets using a training fraction of 0.7\n",
    "  train, test = splitdata_train_test(data, 0.7)\n",
    "\n",
    "  # generate the feature and targets for the training and test sets\n",
    "  # i.e. train_features, train_targets, test_features, test_targets\n",
    "  train_features, train_targets = generate_features_targets(train)\n",
    "  test_features, test_targets = generate_features_targets(test)\n",
    "\n",
    "  # instantiate a decision tree classifier\n",
    "  dtc = DecisionTreeClassifier()\n",
    "\n",
    "  # train the classifier with the train_features and train_targets\n",
    "  dtc.fit(train_features, train_targets)\n",
    "\n",
    "  # get predictions for the test_features\n",
    "  predictions = dtc.predict(test_features)\n",
    "\n",
    "  # return the predictions and the test_targets\n",
    "  return predictions, test_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Some initial results...\n   predicted,  actual\n0. spiral, spiral\n1. merger, spiral\n2. merger, spiral\n3. spiral, spiral\n4. spiral, spiral\n5. merger, spiral\n6. spiral, spiral\n7. spiral, spiral\n8. spiral, spiral\n9. spiral, merger\n"
     ]
    }
   ],
   "source": [
    "data = np.load('galaxy_catalogue.npy')\n",
    "\n",
    "predicted_class, actual_class = dtc_predict_actual(data)\n",
    "\n",
    "# Print some of the initial results\n",
    "print(\"Some initial results...\\n   predicted,  actual\")\n",
    "for i in range(10):\n",
    "    print(\"{}. {}, {}\".format(i, predicted_class[i], actual_class[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}